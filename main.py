import os
import pickle
# from keras.utils import np_utils

import keras
from keras.models import Sequential
from keras.utils import np_utils
from keras.preprocessing.image import ImageDataGenerator
from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization
from keras.layers import Conv2D, MaxPooling2D
from keras.datasets import cifar10
from keras import regularizers
from keras.callbacks import LearningRateScheduler
import numpy as np



def load_normalized_data():
    input_path = os.getcwd() + '/data/'
    # Training and validation files
    files = ['training/train-y', 'training/train-x',
            'validation/test-y', 'validation/test-x']

    # Load training labels
    with open(input_path+files[0], 'rb') as lbpath:
        y_train = pickle.load(lbpath, encoding='bytes')
    # Load training samples
    with open(input_path+files[1], 'rb') as imgpath:
        x_train = pickle.load(imgpath, encoding='bytes')
    # Load validation labels
    with open(input_path+files[2], 'rb') as lbpath:
        y_test = pickle.load(lbpath, encoding='bytes')
    # Load validation samples
    with open(input_path+files[3], 'rb') as imgpath:
        x_test = pickle.load(imgpath, encoding='bytes')

    # Transofrm them to a float32 type
    x_train = x_train.astype('float32')
    x_test = x_test.astype('float32')

    # Normalize the inputs
    x_train /= 255
    x_test  /= 255

    # One-hot Encoding for the labels only
    num_classes = 10
    y_train = np_utils.to_categorical(y_train, num_classes)
    y_test  = np_utils.to_categorical(y_test,  num_classes)

    return x_train, y_train, x_test, y_test


def CNN(input_nodes, output_nodes, x_train, y_train, x_test, y_test):
    # Create the model
    model = Sequential()
    model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_nodes, activation='relu'))
    # model.add(Activation('relu'))
    model.add(Conv2D(32, (3, 3), activation='relu'))
    # model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))

    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))
    # model.add(Activation('relu'))
    model.add(Conv2D(64, (3, 3), activation='relu'))
    # model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))

    model.add(Flatten())
    model.add(Dense(512, activation='relu', dropout='0.5'))
    # model.add(Activation('relu'))
    # model.add(Dropout(0.5))
    model.add(Dense(output_nodes, activation='softmax'))
    # model.add(Activation('softmax'))

    #data augmentation
    datagen = ImageDataGenerator(
                    featurewise_center=False,  # set input mean to 0 over the dataset
                    samplewise_center=False,  # set each sample mean to 0
                    featurewise_std_normalization=False,  # divide inputs by std of the dataset
                    samplewise_std_normalization=False,  # divide each input by its std
                    zca_whitening=False,  # apply ZCA whitening
                    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)
                    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
                    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
                    horizontal_flip=True,  # randomly flip images
                    vertical_flip=False  # randomly flip images
                    )


    # Compute quantities required for feature-wise normalization
    # (std, mean, and principal components if ZCA whitening is applied).
    datagen.fit(x_train)


    # Compile the model
    batch_size = 64

    opt_rms = keras.optimizers.rmsprop(lr=0.001, decay=1e-6)
    model.compile(loss='categorical_crossentropy', 
                  optimizer=opt_rms, 
                  metrics=['accuracy']
                  )

    
    epochs = 20

    # Fit the model on the batches generated by datagen.flow().
    trained_model = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),
                        epochs=epochs,
                        validation_data=(x_test, y_test)
                        )
    
    # evaluate the accuracy
    test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)
    activation_name = 'relu'

    print("\nAccuracy over test set:", test_accuracy)
    plotAccuracy(trained_model, activation_name )
    plotLoss(trained_model, activation_name)


    model_name='cifar-10-cnn-'+str(epochs)
    model_path = os.getcwd() + "/model/"
    model.save(model_path+'/'+model_name+'.hd5') # Keras model
    print("Saved Keras model")

def plotAccuracy(model, activation_name):
    """This plots the training and validation accuracy
    
    Arguments:
        model  -- The model with the accuracies that will be plotted
    """
    
    # get the accuracies from the model
    plt.plot(model.history['acc'],    'blue', label='Training')
    plt.plot(model.history['val_acc'], 'red', label='Validation')
    # prepare the plot
    plt.title('Accuracy for ' + activation_name)
    plt.ylabel('Accuracy (%)')
    plt.xlabel('epochs')
    plt.legend(loc='lower right')
    # plt.ylim(0,1.05)
    #show plot
    # plt.show()
    plt.savefig(activation_name + "accurcy" + ".png")
    plt.close()

def plotLoss(model, activation_name):
    plt.plot(model.history['loss'], 'magenta')
    plt.plot(model.history['val_loss'], 'green')
    plt.title('Loss for '  + activation_name)
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.legend(['Train', 'Test'], loc='upper right')
    # plt.show()
    plt.savefig(activation_name +"loss"+".png")
    plt.close()




def main():
    # load data
    x_train, y_train, x_test, y_test = load_normalized_data()
    
    num_of_inputs = x_train.shape[1:]
    num_of_outputs = len(np.unique(y_train))
    
    # build model
    CNN(num_of_inputs, num_of_outputs, x_train, y_train, x_test, y_test)




if __name__ == "__main__":
    main()